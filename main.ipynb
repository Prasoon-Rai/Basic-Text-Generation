{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eM1PTg8-SAYR"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "print(\"Num GPUs Available: \", len(physical_devices))\n",
        "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "\n",
        "file_path = 'sample_text.txt'\n",
        "with io.open(file_path, encoding='utf-8') as f:\n",
        "    text = f.read()"
      ],
      "metadata": {
        "id": "6J50tJonSrZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "\n",
        "text = text.lower()\n",
        "\n",
        "text = text.replace('\\n', ' ').replace('\\r', ' ')\n",
        "text = re.sub(r'\\s+', ' ', text).strip()"
      ],
      "metadata": {
        "id": "uRPQ-d00StdG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(text)))\n",
        "vocabulary_size = len(chars)\n",
        "\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
        "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
        "\n",
        "print(f\"Total unique characters (vocabulary size): {vocabulary_size}\")"
      ],
      "metadata": {
        "id": "xUH2l5iiSvgp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_length = 70\n",
        "\n",
        "data_X = []\n",
        "data_Y = []\n",
        "\n",
        "for i in range(0, len(text) - sequence_length, 1): # Step by 1 character\n",
        "    seq_in = text[i:i + sequence_length]\n",
        "    seq_out = text[i + sequence_length]\n",
        "    data_X.append([char_to_int[char] for char in seq_in])\n",
        "    data_Y.append(char_to_int[seq_out])\n",
        "\n",
        "n_patterns = len(data_X)\n",
        "print(f\"Total patterns: {n_patterns}\")"
      ],
      "metadata": {
        "id": "a5Ji_Q96Sx3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "X = np.reshape(data_X, (n_patterns, sequence_length, 1))\n",
        "\n",
        "X = X / float(vocabulary_size)\n",
        "\n",
        "X = np.zeros((n_patterns, sequence_length, vocabulary_size), dtype=bool)\n",
        "for i, sequence_ints in enumerate(data_X):\n",
        "    for t, char_int_val in enumerate(sequence_ints):\n",
        "        X[i, t, char_int_val] = 1\n",
        "\n",
        "# One-hot encode the output (Y)\n",
        "y = to_categorical(data_Y, num_classes=vocabulary_size)\n",
        "\n",
        "print(f\"Shape of X (input sequences): {X.shape}\")\n",
        "print(f\"Shape of y (target characters): {y.shape}\")"
      ],
      "metadata": {
        "id": "2zJqH4RqS0ut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import CategoricalCrossentropy\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping"
      ],
      "metadata": {
        "id": "MZp0QejAS1Q1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_length = X.shape[1]\n",
        "vocabulary_size = y.shape[1]"
      ],
      "metadata": {
        "id": "raI4zk30S3KO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential(\n",
        "    [\n",
        "        LSTM(256, input_shape=(sequence_length, vocabulary_size), return_sequences=True),\n",
        "        Dropout(0.2),\n",
        "        LSTM(512),\n",
        "        Dropout(0.2),\n",
        "        Dense(vocabulary_size, activation='softmax')\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "WyimAVuPS5mb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "GDX3vHjzS68I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filepath = \"Basic-Text-Gen-{epoch:02d}-{loss:.4f}.keras\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "model.fit(X, y, epochs=15, validation_split=0.2, batch_size=128, callbacks=callbacks_list)"
      ],
      "metadata": {
        "id": "ZVXn2ViNS8GX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_seed_text = \"the quick brown fox jumps over the lazy dog and wishes for a sunny day\"\n",
        "pattern = [char_to_int[char] for char in custom_seed_text]\n",
        "\n",
        "if len(pattern) != sequence_length:\n",
        "    raise ValueError(f\"Custom seed text length ({len(pattern)}) does not match sequence_length ({sequence_length}).\")\n",
        "\n",
        "seed_text = custom_seed_text # Keep for printing"
      ],
      "metadata": {
        "id": "XmfpAFsJw9Hw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "def sample(preds, temperature=1.0):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "\n",
        "sys.stdout.write(seed_text)\n",
        "\n",
        "generated_text = seed_text\n",
        "\n",
        "num_characters_to_generate = 200\n",
        "\n",
        "for i in range(num_characters_to_generate):\n",
        "    x_pred = np.zeros((1, sequence_length, vocabulary_size), dtype=bool)\n",
        "    for t, char_int in enumerate(pattern):\n",
        "        x_pred[0, t, char_int] = 1\n",
        "\n",
        "    preds = model.predict(x_pred, verbose=0)[0]\n",
        "\n",
        "    next_char_index = sample(preds, temperature=0.7)\n",
        "    next_char = int_to_char[next_char_index]\n",
        "\n",
        "    generated_text += next_char\n",
        "\n",
        "    pattern.append(next_char_index)\n",
        "    pattern = pattern[1:]\n",
        "\n",
        "    sys.stdout.write(next_char)\n",
        "    sys.stdout.flush()"
      ],
      "metadata": {
        "id": "-NYNFsxmw9yt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}